{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio 12.1\n",
    "\n",
    "Tenendo fissi tutti gli altri parametri, variare (almeno 2) la funzione di ottimizzazione.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D\n",
    "from PIL import Image\n",
    "\n",
    "seed=0\n",
    "np.random.seed(seed) # fix random seed\n",
    "tf.set_random_seed(seed)\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28 # number of pixels \n",
    "# output\n",
    "num_classes = 10 # 10 digits\n",
    "# the data, split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows*img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "\n",
    "# cast floats to single precesion\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# rescale data in interval [0,1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# look at an example of data point\n",
    "print('an example of a data point with label', Y_train[20])\n",
    "# matshow: display a matrix in a new figure window\n",
    "\n",
    "#plt.matshow(X_train[20,:].reshape(28,28),cmap='binary')\n",
    "#plt.show()\n",
    "\n",
    "print('an example of a data point with label', Y_train[20], 'before to_categorical ...')\n",
    "# convert class vectors to binary class matrices, e.g. for use with categorical_crossentropy\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "print('... and with label', Y_train[20], 'after to_categorical')\n",
    "print()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "\n",
    "# Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n",
    "labels = np.array([0, 2, 1, 2, 0])\n",
    "# `to_categorical` converts this into a matrix with as many columns as there are classes.\n",
    "# The number of rows stays the same.\n",
    "keras.utils.to_categorical(labels)\n",
    "\n",
    "def create_DNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(400,input_shape=(img_rows*img_cols,), activation='relu'))\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "print('Model architecture created successfully!')\n",
    "\n",
    "def compile_model():\n",
    "    # create the model\n",
    "    model=create_DNN()\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                 # optimizer=Adadelta(),\n",
    "                 # optimizer=Adagrad(),\n",
    "                   optimizer= Adam(),\n",
    "                 # optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.01, decay = 1e-6, momentum=0.9, nesterov=True)\n",
    "keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "print('Model compiled successfully and ready to be trained.')\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "# create the deep neural net\n",
    "model_DNN = compile_model()\n",
    "\n",
    "# train DNN and store training info in history\n",
    "history = model_DNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model_DNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# look into training history\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "predictions = model_DNN.predict(X_test)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "plt.figure(figsize=(15, 15)) \n",
    "for i in range(10):    \n",
    "    ax = plt.subplot(2, 10, i + 1)    \n",
    "    plt.imshow(X_test[i, :, :, 0], cmap='gray')    \n",
    "    plt.title(\"Digit: {}\\nPredicted:    {}\".format(np.argmax(Y_test[i]), np.argmax(predictions[i])))    \n",
    "    plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho utilizzato :\n",
    " \n",
    "- Adagard;\n",
    "- Adam;\n",
    "- Adadelta;\n",
    "- GD;\n",
    "\n",
    "Ho visto che questi optimizer dipendono molto dalla scelta del learning rate. In generale se si sceglie un lr troppo piccolo (es: lr= 0.00001) la rete non apprende, se si sceglie un lr troppo grande (es: lr=100) la rete non converge. In assoluto non c'è un lr che vada bene per tutti gli optimizer, ho quindi utilizzato learning rate diversi a seconda della funzione. \n",
    "\n",
    "Per scegliere il miglior optimizer ho poi guardato quello che aveva le migliori performance. Mi è sembrato che Adam fosse il migliore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio 12.2\n",
    "\n",
    "Utilizzre i convolutional layers (`Conv2D`, `MaxPooling2D`, `Dropout`) per determinare il numero nelle immagini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "np.random.seed(seed) # fix random seed\n",
    "tf.set_random_seed(seed)\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28 # number of pixels \n",
    "# output\n",
    "num_classes = 10 # 10 digits\n",
    "# the data, split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows*img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "\n",
    "# cast floats to single precesion\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# rescale data in interval [0,1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# look at an example of data point\n",
    "print('an example of a data point with label', Y_train[20])\n",
    "# matshow: display a matrix in a new figure window\n",
    "\n",
    "#plt.matshow(X_train[20,:].reshape(28,28),cmap='binary')\n",
    "#plt.show()\n",
    "\n",
    "print('an example of a data point with label', Y_train[20], 'before to_categorical ...')\n",
    "# convert class vectors to binary class matrices, e.g. for use with categorical_crossentropy\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "print('... and with label', Y_train[20], 'after to_categorical')\n",
    "print()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "\n",
    "# Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n",
    "labels = np.array([0, 2, 1, 2, 0])\n",
    "# `to_categorical` converts this into a matrix with as many columns as there are classes.\n",
    "# The number of rows stays the same.\n",
    "keras.utils.to_categorical(labels)\n",
    "\n",
    "# reshape data, depending on Keras backend\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "def create_CNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add first convolutional layer with 10 filters (dimensionality of output space)\n",
    "    model.add(Conv2D(32,(5,5),activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(300))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # ADD HERE SOME OTHER LAYERS AT YOUR WILL, FOR EXAMPLE SOME: Dropout, 2D pooling, 2D convolutional etc. ... \n",
    "    # remember to move towards a standard flat layer in the final part of your DNN,\n",
    "    # and that we need a soft-max layer with num_classes=10 possible outputs\n",
    "    #\n",
    "    opt = adam(lr=0.001, decay=1e-6)\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer= opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# create the deep conv net\n",
    "model_CNN=create_CNN()\n",
    "\n",
    "# train CNN\n",
    "model_CNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "# evaliate model\n",
    "score = model_CNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "predictions = model_CNN.predict(X_test)\n",
    "\n",
    "score = model_CNN.evaluate(X_test, predictions, verbose=1)\n",
    "\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "\n",
    "digit_filename = \"./Pictures/9b.png\"\n",
    "digit_in = Image.open(digit_filename).convert('L')\n",
    "\n",
    "ydim, xdim = digit_in.size\n",
    "print(\"Image size: \"+str(xdim)+\"x\"+str(ydim))\n",
    "pix=digit_in.load();\n",
    "data = np.zeros((xdim, ydim))\n",
    "for j in range(ydim):\n",
    "    for i in range(xdim):\n",
    "        data[i,j]=pix[j,i]\n",
    "\n",
    "data /= 255\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(data, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data = data.reshape(1,xdim*ydim)\n",
    "print(data.shape)\n",
    "pred_0 = model_DNN.predict(data)\n",
    "\n",
    "data = data.reshape(xdim,ydim)\n",
    "\n",
    "plt.figure(figsize=(5, 5))  \n",
    "plt.imshow(data, cmap='gray')    \n",
    "plt.title(\"Digit predicted:    {}\".format(np.argmax(pred_0)))\n",
    "plt.axis('off') \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
